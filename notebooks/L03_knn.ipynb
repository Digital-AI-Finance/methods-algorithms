{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Classification\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/methods-algorithms/blob/master/notebooks/L03_knn.ipynb)\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand how KNN classifies new data points using neighbor voting\n",
    "- Visualize decision boundaries and see how K affects model complexity\n",
    "- Learn why feature scaling is critical for distance-based methods\n",
    "- Use cross-validation to select the optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "})\n",
    "\n",
    "# ML color palette\n",
    "ML_PURPLE = '#3333B2'\n",
    "ML_BLUE = '#0066CC'\n",
    "ML_ORANGE = '#FF7F0E'\n",
    "ML_GREEN = '#2CA02C'\n",
    "ML_RED = '#D62728'\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2-class dataset with 2 features for easy visualization\n",
    "X, y = make_classification(\n",
    "    n_samples=200, n_features=2, n_redundant=0, n_informative=2,\n",
    "    n_clusters_per_class=1, flip_y=0.1, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Test samples:     {len(X_test)}')\n",
    "print(f'Class distribution: {np.bincount(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 1: Scatter plot of raw data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(X[:, 0], X[:, 1], c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y],\n",
    "                     edgecolors='white', s=60, alpha=0.8)\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.set_title('Two-Class Dataset')\n",
    "ax.legend(handles=[\n",
    "    mpatches.Patch(color=ML_BLUE, label='Class 0'),\n",
    "    mpatches.Patch(color=ML_ORANGE, label='Class 1')\n",
    "], loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How KNN Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 2: Show a query point and its K=3 nearest neighbors\n",
    "query_point = np.array([[0.5, 0.5]])\n",
    "\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X_train, y_train)\n",
    "\n",
    "distances, indices = knn_3.kneighbors(query_point)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1],\n",
    "           c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y_train],\n",
    "           edgecolors='white', s=50, alpha=0.5)\n",
    "\n",
    "# Highlight the K=3 nearest neighbors\n",
    "for idx, dist in zip(indices[0], distances[0]):\n",
    "    neighbor = X_train[idx]\n",
    "    color = ML_BLUE if y_train[idx] == 0 else ML_ORANGE\n",
    "    ax.scatter(neighbor[0], neighbor[1], c=color, s=200, edgecolors='black', linewidths=2, zorder=5)\n",
    "    ax.plot([query_point[0, 0], neighbor[0]], [query_point[0, 1], neighbor[1]],\n",
    "            'k--', alpha=0.6, linewidth=1.5)\n",
    "    mid_x = (query_point[0, 0] + neighbor[0]) / 2\n",
    "    mid_y = (query_point[0, 1] + neighbor[1]) / 2\n",
    "    ax.annotate(f'd={dist:.2f}', (mid_x, mid_y), fontsize=9,\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Draw circle around query point encompassing all 3 neighbors\n",
    "radius = distances[0].max() * 1.05\n",
    "circle = plt.Circle(query_point[0], radius, fill=False, color=ML_RED,\n",
    "                     linestyle='--', linewidth=2)\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# Query point\n",
    "ax.scatter(query_point[0, 0], query_point[0, 1], c=ML_RED, marker='*',\n",
    "           s=400, edgecolors='black', linewidths=1.5, zorder=10, label='Query point')\n",
    "\n",
    "pred = knn_3.predict(query_point)[0]\n",
    "ax.set_title(f'KNN with K=3: Query Point Classified as Class {pred}')\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 3: Decision boundaries for K=1, K=5, K=15\n",
    "def plot_decision_boundary(ax, X, y, k, title):\n",
    "    h = 0.05\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X, y)\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    cmap_bg = ListedColormap(['#cce0ff', '#ffe0cc'])\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_bg)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y],\n",
    "               edgecolors='white', s=30, alpha=0.8)\n",
    "    acc = knn.score(X, y)\n",
    "    ax.set_title(f'{title}\\nTrain Acc: {acc:.2f}')\n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for ax, k, title in zip(axes, [1, 5, 15], ['K=1 (Overfitting)', 'K=5 (Balanced)', 'K=15 (Underfitting)']):\n",
    "    plot_decision_boundary(ax, X_train, y_train, k, title)\n",
    "plt.suptitle('Effect of K on Decision Boundaries', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 4: Before/after scaling comparison\n",
    "# Create data with very different scales\n",
    "X_unscaled = X_train.copy()\n",
    "X_unscaled[:, 0] = X_unscaled[:, 0] * 1000  # Feature 1 in range ~[-3000, 3000]\n",
    "X_unscaled[:, 1] = X_unscaled[:, 1] * 0.01   # Feature 2 in range ~[-0.03, 0.03]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_unscaled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Unscaled\n",
    "axes[0].scatter(X_unscaled[:, 0], X_unscaled[:, 1],\n",
    "                c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y_train],\n",
    "                edgecolors='white', s=50, alpha=0.7)\n",
    "axes[0].set_title('Before Scaling (Unscaled)')\n",
    "axes[0].set_xlabel(f'Feature 1 (range: {X_unscaled[:, 0].min():.0f} to {X_unscaled[:, 0].max():.0f})')\n",
    "axes[0].set_ylabel(f'Feature 2 (range: {X_unscaled[:, 1].min():.3f} to {X_unscaled[:, 1].max():.3f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].annotate('Feature 1 dominates\\ndistance calculations!',\n",
    "                 xy=(0.5, 0.05), xycoords='axes fraction', fontsize=11,\n",
    "                 ha='center', color=ML_RED, fontweight='bold',\n",
    "                 bbox=dict(boxstyle='round', facecolor='lightyellow'))\n",
    "\n",
    "# Scaled\n",
    "axes[1].scatter(X_scaled[:, 0], X_scaled[:, 1],\n",
    "                c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y_train],\n",
    "                edgecolors='white', s=50, alpha=0.7)\n",
    "axes[1].set_title('After StandardScaler')\n",
    "axes[1].set_xlabel('Feature 1 (standardized)')\n",
    "axes[1].set_ylabel('Feature 2 (standardized)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].annotate('Both features contribute\\nequally to distances',\n",
    "                 xy=(0.5, 0.05), xycoords='axes fraction', fontsize=11,\n",
    "                 ha='center', color=ML_GREEN, fontweight='bold',\n",
    "                 bbox=dict(boxstyle='round', facecolor='lightyellow'))\n",
    "\n",
    "plt.suptitle('Why Feature Scaling Matters for KNN', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding the Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 5: Cross-validation accuracy curve\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "k_range = range(1, 21)\n",
    "cv_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_s, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "best_k = list(k_range)[np.argmax(cv_scores)]\n",
    "best_score = max(cv_scores)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(list(k_range), cv_scores, 'o-', color=ML_PURPLE, linewidth=2, markersize=6)\n",
    "ax.axvline(x=best_k, color=ML_RED, linestyle='--', linewidth=2, label=f'Best K={best_k}')\n",
    "ax.scatter([best_k], [best_score], color=ML_RED, s=200, zorder=5, edgecolors='black')\n",
    "ax.annotate(f'Best K={best_k}\\nAcc={best_score:.3f}',\n",
    "            xy=(best_k, best_score), xytext=(best_k + 2, best_score - 0.02),\n",
    "            fontsize=11, arrowprops=dict(arrowstyle='->', color='black'),\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow'))\n",
    "ax.set_xlabel('K (Number of Neighbors)')\n",
    "ax.set_ylabel('5-Fold Cross-Validation Accuracy')\n",
    "ax.set_title('Selecting the Optimal K via Cross-Validation')\n",
    "ax.set_xticks(list(k_range))\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Best K: {best_k} with CV accuracy: {best_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 6: Unit balls for Euclidean, Manhattan, Chebyshev\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "theta = np.linspace(0, 2 * np.pi, 500)\n",
    "\n",
    "# Euclidean (L2) - circle\n",
    "x_l2 = np.cos(theta)\n",
    "y_l2 = np.sin(theta)\n",
    "axes[0].fill(x_l2, y_l2, alpha=0.3, color=ML_BLUE)\n",
    "axes[0].plot(x_l2, y_l2, color=ML_BLUE, linewidth=2)\n",
    "axes[0].set_title('Euclidean (p=2)\\nCircle', fontsize=13)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].annotate(r'$d = \\sqrt{\\sum(x_i - y_i)^2}$', xy=(0, -0.3),\n",
    "                 fontsize=12, ha='center')\n",
    "\n",
    "# Manhattan (L1) - diamond\n",
    "t = np.linspace(0, 2 * np.pi, 500)\n",
    "x_l1 = np.sign(np.cos(t)) * (1 - np.abs(np.sin(t)))\n",
    "# Parametric diamond\n",
    "x_l1 = np.array([1, 0, -1, 0, 1])\n",
    "y_l1 = np.array([0, 1, 0, -1, 0])\n",
    "axes[1].fill(x_l1, y_l1, alpha=0.3, color=ML_ORANGE)\n",
    "axes[1].plot(x_l1, y_l1, color=ML_ORANGE, linewidth=2)\n",
    "axes[1].set_title('Manhattan (p=1)\\nDiamond', fontsize=13)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].annotate(r'$d = \\sum|x_i - y_i|$', xy=(0, -0.3),\n",
    "                 fontsize=12, ha='center')\n",
    "\n",
    "# Chebyshev (L-inf) - square\n",
    "x_linf = np.array([1, 1, -1, -1, 1])\n",
    "y_linf = np.array([1, -1, -1, 1, 1])\n",
    "axes[2].fill(x_linf, y_linf, alpha=0.3, color=ML_GREEN)\n",
    "axes[2].plot(x_linf, y_linf, color=ML_GREEN, linewidth=2)\n",
    "axes[2].set_title(r'Chebyshev ($p=\\infty$)' + '\\nSquare', fontsize=13)\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].annotate(r'$d = \\max|x_i - y_i|$', xy=(0, -0.3),\n",
    "                 fontsize=12, ha='center')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(-1.5, 1.5)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.axhline(0, color='gray', linewidth=0.5)\n",
    "    ax.axvline(0, color='gray', linewidth=0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "plt.suptitle('Unit Balls for Different Distance Metrics', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final KNN with best K\n",
    "knn_final = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_final.fit(X_train_s, y_train)\n",
    "\n",
    "y_pred = knn_final.predict(X_test_s)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test Accuracy with K={best_k}: {acc:.3f}')\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 7: Decision boundary with test points overlaid\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "h = 0.05\n",
    "x_min, x_max = X_train_s[:, 0].min() - 1, X_train_s[:, 0].max() + 1\n",
    "y_min, y_max = X_train_s[:, 1].min() - 1, X_train_s[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = knn_final.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "cmap_bg = ListedColormap(['#cce0ff', '#ffe0cc'])\n",
    "ax.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_bg)\n",
    "\n",
    "# Training points (small, faded)\n",
    "ax.scatter(X_train_s[:, 0], X_train_s[:, 1],\n",
    "           c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y_train],\n",
    "           s=20, alpha=0.3, label='Train')\n",
    "\n",
    "# Test points (large, bold)\n",
    "ax.scatter(X_test_s[:, 0], X_test_s[:, 1],\n",
    "           c=[ML_BLUE if yi == 0 else ML_ORANGE for yi in y_test],\n",
    "           s=80, edgecolors='black', linewidths=1.5, alpha=0.9, label='Test')\n",
    "\n",
    "# Mark misclassified\n",
    "misclassified = y_test != y_pred\n",
    "if misclassified.any():\n",
    "    ax.scatter(X_test_s[misclassified, 0], X_test_s[misclassified, 1],\n",
    "               facecolors='none', edgecolors=ML_RED, s=200, linewidths=2.5,\n",
    "               label='Misclassified')\n",
    "\n",
    "ax.set_xlabel('Feature 1 (scaled)')\n",
    "ax.set_ylabel('Feature 2 (scaled)')\n",
    "ax.set_title(f'Final KNN (K={best_k}) Decision Boundary with Test Points')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual 8: Confusion matrix heatmap\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.set_title(f'Confusion Matrix (K={best_k})', fontsize=14)\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "classes = ['Class 0', 'Class 1']\n",
    "tick_marks = [0, 1]\n",
    "ax.set_xticks(tick_marks)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticks(tick_marks)\n",
    "ax.set_yticklabels(classes)\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center',\n",
    "                fontsize=20, fontweight='bold',\n",
    "                color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **KNN is a lazy learner** -- it stores all training data and classifies new points by majority vote among the K nearest neighbors\n",
    "- **K controls the bias-variance tradeoff**: small K = complex boundary (overfitting), large K = smooth boundary (underfitting)\n",
    "- **Feature scaling is essential** because KNN relies on distances -- unscaled features with larger ranges dominate the distance calculation\n",
    "- **Use cross-validation** to find the optimal K rather than guessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}