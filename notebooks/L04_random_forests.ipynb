{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# L04: Random Forests\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/methods-algorithms/blob/master/notebooks/L04_random_forests.ipynb)\n\n**Course**: Methods and Algorithms - MSc Data Science\n\n---\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n\n1. Build decision trees and understand splitting criteria\n2. Implement Random Forests with bootstrap and feature randomization\n3. Interpret feature importance for business decisions\n4. Use OOB error for model validation"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Generate Fraud Detection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate fraud detection dataset\n",
    "n_samples = 1000\n",
    "fraud_rate = 0.1\n",
    "\n",
    "n_fraud = int(n_samples * fraud_rate)\n",
    "n_normal = n_samples - n_fraud\n",
    "\n",
    "# Normal transactions\n",
    "normal_data = {\n",
    "    'amount': np.random.lognormal(4, 1, n_normal),\n",
    "    'hour': np.random.choice(range(8, 22), n_normal),\n",
    "    'is_foreign': np.random.binomial(1, 0.1, n_normal),\n",
    "    'previous_fraud': np.random.binomial(1, 0.02, n_normal),\n",
    "    'account_age_days': np.random.randint(100, 2000, n_normal),\n",
    "    'transaction_freq': np.random.uniform(5, 20, n_normal),\n",
    "    'device_changed': np.random.binomial(1, 0.05, n_normal),\n",
    "    'location_distance': np.random.exponential(20, n_normal),\n",
    "    'is_fraud': np.zeros(n_normal)\n",
    "}\n",
    "\n",
    "# Fraudulent transactions (different patterns)\n",
    "fraud_data = {\n",
    "    'amount': np.random.lognormal(6, 1.5, n_fraud),\n",
    "    'hour': np.random.choice([0, 1, 2, 3, 4, 22, 23], n_fraud),\n",
    "    'is_foreign': np.random.binomial(1, 0.7, n_fraud),\n",
    "    'previous_fraud': np.random.binomial(1, 0.3, n_fraud),\n",
    "    'account_age_days': np.random.randint(10, 100, n_fraud),\n",
    "    'transaction_freq': np.random.uniform(0.5, 3, n_fraud),\n",
    "    'device_changed': np.random.binomial(1, 0.6, n_fraud),\n",
    "    'location_distance': np.random.exponential(500, n_fraud),\n",
    "    'is_fraud': np.ones(n_fraud)\n",
    "}\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([pd.DataFrame(normal_data), pd.DataFrame(fraud_data)], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Fraud rate: {df.is_fraud.mean():.1%}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Amount distribution\n",
    "axes[0, 0].hist(df[df.is_fraud==0].amount, bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "axes[0, 0].hist(df[df.is_fraud==1].amount, bins=30, alpha=0.6, label='Fraud', color='red')\n",
    "axes[0, 0].set_xlabel('Transaction Amount')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_title('Amount Distribution')\n",
    "\n",
    "# Hour distribution\n",
    "axes[0, 1].hist(df[df.is_fraud==0].hour, bins=24, alpha=0.6, label='Normal', color='blue')\n",
    "axes[0, 1].hist(df[df.is_fraud==1].hour, bins=24, alpha=0.6, label='Fraud', color='red')\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_title('Transaction Hour')\n",
    "\n",
    "# Account age vs Amount\n",
    "scatter = axes[1, 0].scatter(df.account_age_days, df.amount, c=df.is_fraud, \n",
    "                             cmap='coolwarm', alpha=0.5, s=30)\n",
    "axes[1, 0].set_xlabel('Account Age (days)')\n",
    "axes[1, 0].set_ylabel('Amount')\n",
    "axes[1, 0].set_title('Account Age vs Amount')\n",
    "\n",
    "# Location distance\n",
    "axes[1, 1].hist(df[df.is_fraud==0].location_distance, bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "axes[1, 1].hist(df[df.is_fraud==1].location_distance, bins=30, alpha=0.6, label='Fraud', color='red')\n",
    "axes[1, 1].set_xlabel('Location Distance (km)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_title('Location Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "feature_cols = ['amount', 'hour', 'is_foreign', 'previous_fraud', \n",
    "                'account_age_days', 'transaction_freq', 'device_changed', 'location_distance']\n",
    "X = df[feature_cols].values\n",
    "y = df['is_fraud'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training samples: {len(X_train)}')\n",
    "print(f'Test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single decision tree\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = tree.score(X_train, y_train)\n",
    "test_acc = tree.score(X_test, y_test)\n",
    "\n",
    "print(f'Single Tree - Train Accuracy: {train_acc:.3f}')\n",
    "print(f'Single Tree - Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree, feature_names=feature_cols, class_names=['Normal', 'Fraud'],\n",
    "          filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree for Fraud Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show tree variance - train on different samples\n",
    "accuracies = []\n",
    "for seed in range(20):\n",
    "    X_sample, _, y_sample, _ = train_test_split(X_train, y_train, \n",
    "                                                 test_size=0.5, random_state=seed)\n",
    "    tree_temp = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "    tree_temp.fit(X_sample, y_sample)\n",
    "    accuracies.append(tree_temp.score(X_test, y_test))\n",
    "\n",
    "print(f'Single Tree Variance: {np.std(accuracies):.3f}')\n",
    "print(f'Accuracy Range: [{min(accuracies):.3f}, {max(accuracies):.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest with OOB score\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features='sqrt',\n",
    "                            oob_score=True, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = rf.score(X_train, y_train)\n",
    "test_acc = rf.score(X_test, y_test)\n",
    "oob_score = rf.oob_score_\n",
    "\n",
    "print(f'Random Forest - Train Accuracy: {train_acc:.3f}')\n",
    "print(f'Random Forest - OOB Score: {oob_score:.3f}')\n",
    "print(f'Random Forest - Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOB error vs number of trees\n",
    "oob_errors = []\n",
    "n_trees_range = range(1, 201, 10)\n",
    "\n",
    "for n_trees in n_trees_range:\n",
    "    rf_temp = RandomForestClassifier(n_estimators=n_trees, max_features='sqrt',\n",
    "                                     oob_score=True, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    oob_errors.append(1 - rf_temp.oob_score_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_trees_range, oob_errors, 'o-', linewidth=2, markersize=6)\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('OOB Error Rate')\n",
    "plt.title('OOB Error vs Number of Trees')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 4. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_cols)), importances[indices], align='center')\n",
    "plt.yticks(range(len(feature_cols)), [feature_cols[i] for i in indices])\n",
    "plt.xlabel('Mean Decrease in Impurity')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print ranking\n",
    "print('\\nFeature Importance Ranking:')\n",
    "for i in indices[::-1]:\n",
    "    print(f'  {feature_cols[i]}: {importances[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business interpretation\n",
    "print('\\n=== Business Interpretation ===')\n",
    "print('\\nTop Fraud Indicators:')\n",
    "\n",
    "top_features = [(feature_cols[i], importances[i]) for i in indices[::-1][:4]]\n",
    "strategies = {\n",
    "    'location_distance': 'Flag transactions >500km from usual location',\n",
    "    'amount': 'Review transactions >$1000, especially for new accounts',\n",
    "    'account_age_days': 'New accounts (<100 days) require extra verification',\n",
    "    'is_foreign': 'Foreign transactions need additional authentication',\n",
    "    'device_changed': 'Send verification when new device detected',\n",
    "    'hour': 'Flag transactions between midnight and 5am',\n",
    "    'transaction_freq': 'Monitor sudden changes in transaction frequency',\n",
    "    'previous_fraud': 'High-risk customers need enhanced monitoring'\n",
    "}\n",
    "\n",
    "for feature, importance in top_features:\n",
    "    print(f'\\n{feature} (importance: {importance:.3f})')\n",
    "    print(f'  Strategy: {strategies.get(feature, \"N/A\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare single tree vs random forest\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Predictions\n",
    "tree_proba = tree.predict_proba(X_test)[:, 1]\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ROC curves\n",
    "tree_fpr, tree_tpr, _ = roc_curve(y_test, tree_proba)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba)\n",
    "\n",
    "tree_auc = roc_auc_score(y_test, tree_proba)\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(tree_fpr, tree_tpr, label=f'Single Tree (AUC = {tree_auc:.3f})', linewidth=2)\n",
    "plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_auc:.3f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for Random Forest\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Random Forest)')\n",
    "plt.xticks([0, 1], ['Normal', 'Fraud'])\n",
    "plt.yticks([0, 1], ['Normal', 'Fraud'])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Hyperparameter Tuning\n",
    "Tune `max_features` using OOB error. Compare 'sqrt', 'log2', and 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# Solution: Compare different max_features values using OOB score\nfrom sklearn.model_selection import GridSearchCV\n\n# Method 1: Manual comparison using OOB score\nmax_features_options = ['sqrt', 'log2', 0.3]\nresults = []\n\nprint(\"Comparing max_features using OOB Score:\")\nprint(\"-\" * 45)\n\nfor mf in max_features_options:\n    rf_temp = RandomForestClassifier(\n        n_estimators=100,\n        max_features=mf,\n        oob_score=True,\n        random_state=42,\n        n_jobs=-1\n    )\n    rf_temp.fit(X_train, y_train)\n    test_acc = rf_temp.score(X_test, y_test)\n    results.append({\n        'max_features': mf,\n        'oob_score': rf_temp.oob_score_,\n        'test_accuracy': test_acc\n    })\n    print(f\"max_features={str(mf):6s}: OOB={rf_temp.oob_score_:.3f}, Test Acc={test_acc:.3f}\")\n\n# Method 2: Grid search with cross-validation\nprint(\"\\nGrid Search with Cross-Validation:\")\nprint(\"-\" * 45)\n\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [5, 10, None],\n    'min_samples_split': [2, 5, 10]\n}\n\ngrid_search = GridSearchCV(\n    RandomForestClassifier(random_state=42, oob_score=True),\n    param_grid,\n    cv=5,\n    scoring='accuracy',\n    n_jobs=-1\n)\ngrid_search.fit(X_train, y_train)\n\nprint(f\"Best parameters: {grid_search.best_params_}\")\nprint(f\"Best CV score: {grid_search.best_score_:.3f}\")\nprint(f\"Test accuracy with best params: {grid_search.score(X_test, y_test):.3f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Exercise 2: Permutation Importance\n",
    "Calculate permutation importance and compare to MDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "# Solution: Calculate permutation importance and compare to MDI\nfrom sklearn.inspection import permutation_importance\n\n# Calculate permutation importance on test set\nperm_importance = permutation_importance(\n    rf, X_test, y_test,\n    n_repeats=10,\n    random_state=42,\n    n_jobs=-1\n)\n\n# Create comparison dataframe\ncomparison_df = pd.DataFrame({\n    'Feature': feature_cols,\n    'MDI (Mean Decrease Impurity)': rf.feature_importances_,\n    'Permutation Importance': perm_importance.importances_mean,\n    'Perm Std': perm_importance.importances_std\n})\ncomparison_df = comparison_df.sort_values('Permutation Importance', ascending=False)\n\nprint(\"Feature Importance Comparison: MDI vs Permutation\")\nprint(\"=\" * 65)\nprint(comparison_df.to_string(index=False))\n\n# Visualize comparison\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# MDI importance\nax1 = axes[0]\nindices_mdi = np.argsort(rf.feature_importances_)\nax1.barh(range(len(feature_cols)), rf.feature_importances_[indices_mdi], color='steelblue')\nax1.set_yticks(range(len(feature_cols)))\nax1.set_yticklabels([feature_cols[i] for i in indices_mdi])\nax1.set_xlabel('Mean Decrease in Impurity')\nax1.set_title('MDI Feature Importance')\n\n# Permutation importance\nax2 = axes[1]\nindices_perm = np.argsort(perm_importance.importances_mean)\nax2.barh(range(len(feature_cols)), perm_importance.importances_mean[indices_perm],\n         xerr=perm_importance.importances_std[indices_perm], color='darkorange', capsize=3)\nax2.set_yticks(range(len(feature_cols)))\nax2.set_yticklabels([feature_cols[i] for i in indices_perm])\nax2.set_xlabel('Mean Accuracy Decrease')\nax2.set_title('Permutation Feature Importance')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nKey Insight: Permutation importance is generally more reliable than MDI\")\nprint(\"because MDI can be biased toward high-cardinality features.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "1. **Decision Trees** split data using impurity criteria (Gini, entropy)\n",
    "2. **Random Forests** combine many trees with bootstrap + feature randomization\n",
    "3. **OOB Error** provides free cross-validation estimate\n",
    "4. **Feature Importance** helps interpret and explain model decisions\n",
    "5. **Ensembles** reduce variance without increasing bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}